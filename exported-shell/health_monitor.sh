#!/bin/bash
# Generated by SwarmSH v2 Shell Exporter - Health Monitoring Module
# Health Monitor with Bottleneck Detection - $(date)
# Version: 2.0.0

set -euo pipefail

# SwarmSH v2 Health Monitoring System
# Adaptive monitoring with DLSS optimization principles

# Configuration
HEALTH_CHECK_INTERVAL="${HEALTH_CHECK_INTERVAL:-10}"
HEALTH_DATA_DIR="${HEALTH_DATA_DIR:-/tmp/swarmsh_health}"
BOTTLENECK_THRESHOLD="${BOTTLENECK_THRESHOLD:-0.8}"
TELEMETRY_SCRIPT="${TELEMETRY_SCRIPT:-./swarmsh_telemetry.sh}"

# Ensure health data directory exists
mkdir -p "$HEALTH_DATA_DIR"/{agents,work,system,bottlenecks}

# Health status enum
readonly STATUS_HEALTHY="healthy"
readonly STATUS_DEGRADED="degraded"
readonly STATUS_CRITICAL="critical"

# Component health check
check_component_health() {
    local component="$1"
    local check_type="${2:-basic}"
    
    case "$component" in
        "coordinator")
            check_coordinator_health "$check_type"
            ;;
        "agents")
            check_agents_health "$check_type"
            ;;
        "work_queue")
            check_work_queue_health "$check_type"
            ;;
        "telemetry")
            check_telemetry_health "$check_type"
            ;;
        "system")
            check_system_health "$check_type"
            ;;
        *)
            echo "Unknown component: $component"
            return 1
            ;;
    esac
}

# Coordinator health check
check_coordinator_health() {
    local check_type="$1"
    local status=$STATUS_HEALTHY
    local issues=()
    
    # Check coordination lock files
    local lock_count=$(find /tmp -name "swarmsh_lock_*" -mmin -1 2>/dev/null | wc -l)
    if [[ $lock_count -gt 100 ]]; then
        status=$STATUS_DEGRADED
        issues+=("High lock contention: $lock_count active locks")
    fi
    
    # Check coordination patterns
    for pattern in scrum_at_scale roberts_rules realtime atomic; do
        if ! check_pattern_health "$pattern"; then
            status=$STATUS_DEGRADED
            issues+=("Pattern $pattern unhealthy")
        fi
    done
    
    # Record health status
    record_health_status "coordinator" "$status" "${issues[@]}"
    echo "$status"
}

# Agent health check
check_agents_health() {
    local check_type="$1"
    local status=$STATUS_HEALTHY
    local active_agents=0
    local unhealthy_agents=0
    
    # Check all registered agents
    for agent_file in /tmp/swarmsh_agents/*/config.json; do
        [[ -f "$agent_file" ]] || continue
        
        local agent_id=$(jq -r '.agent_id' "$agent_file" 2>/dev/null)
        local last_heartbeat=$(find "$(dirname "$agent_file")" -name "heartbeat" -mmin -1 2>/dev/null | wc -l)
        
        if [[ $last_heartbeat -eq 0 ]]; then
            ((unhealthy_agents++))
            record_agent_health "$agent_id" $STATUS_CRITICAL "No recent heartbeat"
        else
            ((active_agents++))
            record_agent_health "$agent_id" $STATUS_HEALTHY ""
        fi
    done
    
    # Determine overall status
    if [[ $unhealthy_agents -gt 0 ]]; then
        if [[ $active_agents -eq 0 ]]; then
            status=$STATUS_CRITICAL
        else
            status=$STATUS_DEGRADED
        fi
    fi
    
    record_health_status "agents" "$status" \
        "Active: $active_agents, Unhealthy: $unhealthy_agents"
    echo "$status"
}

# Work queue health check
check_work_queue_health() {
    local check_type="$1"
    local status=$STATUS_HEALTHY
    local work_dir="${WORK_DIR:-/tmp/swarmsh_work}"
    
    # Count work items by status
    local pending=$(find "$work_dir" -name "*.todo" 2>/dev/null | wc -l)
    local claimed=$(find "$work_dir" -name "*.claimed_*" 2>/dev/null | wc -l)
    local completed=$(find "$work_dir" -name "*.completed_*" 2>/dev/null | wc -l)
    local stuck=$(find "$work_dir" -name "*.claimed_*" -mmin +30 2>/dev/null | wc -l)
    
    # Check for bottlenecks
    if [[ $stuck -gt 0 ]]; then
        status=$STATUS_DEGRADED
        detect_bottleneck "work_queue" "stuck_work" "$stuck work items stuck >30min"
    fi
    
    if [[ $pending -gt 100 ]]; then
        status=$STATUS_DEGRADED
        detect_bottleneck "work_queue" "backlog" "$pending items pending"
    fi
    
    # Record metrics
    if [[ -x "$TELEMETRY_SCRIPT" ]]; then
        "$TELEMETRY_SCRIPT" metric "swarmsh.work.queue.pending" "$pending" "gauge"
        "$TELEMETRY_SCRIPT" metric "swarmsh.work.queue.claimed" "$claimed" "gauge"
        "$TELEMETRY_SCRIPT" metric "swarmsh.work.queue.stuck" "$stuck" "gauge"
    fi
    
    record_health_status "work_queue" "$status" \
        "Pending: $pending, Claimed: $claimed, Stuck: $stuck"
    echo "$status"
}

# Telemetry health check
check_telemetry_health() {
    local check_type="$1"
    local status=$STATUS_HEALTHY
    local telemetry_dir="${TELEMETRY_DIR:-/tmp/swarmsh_telemetry}"
    
    # Check telemetry data accumulation
    local span_count=$(find "$telemetry_dir/spans" -name "*.json" 2>/dev/null | wc -l)
    local metric_count=$(find "$telemetry_dir/metrics" -name "*.json" 2>/dev/null | wc -l)
    
    if [[ $span_count -gt 10000 ]]; then
        status=$STATUS_DEGRADED
        detect_bottleneck "telemetry" "span_accumulation" "$span_count spans not exported"
    fi
    
    # Check daemon status
    if [[ -f "$telemetry_dir/daemon.pid" ]]; then
        local daemon_pid=$(cat "$telemetry_dir/daemon.pid")
        if ! kill -0 "$daemon_pid" 2>/dev/null; then
            status=$STATUS_DEGRADED
            record_health_status "telemetry" "$status" "Daemon not running"
        fi
    fi
    
    record_health_status "telemetry" "$status" \
        "Spans: $span_count, Metrics: $metric_count"
    echo "$status"
}

# System health check
check_system_health() {
    local check_type="$1"
    local status=$STATUS_HEALTHY
    local issues=()
    
    # CPU usage
    local cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1 2>/dev/null || echo "0")
    if (( $(echo "$cpu_usage > 80" | bc -l 2>/dev/null || echo 0) )); then
        status=$STATUS_DEGRADED
        issues+=("High CPU usage: ${cpu_usage}%")
        detect_bottleneck "system" "cpu" "CPU usage ${cpu_usage}%"
    fi
    
    # Memory usage
    local mem_usage=$(free | grep Mem | awk '{print ($3/$2) * 100.0}' 2>/dev/null || echo "0")
    if (( $(echo "$mem_usage > 90" | bc -l 2>/dev/null || echo 0) )); then
        status=$STATUS_DEGRADED
        issues+=("High memory usage: ${mem_usage}%")
        detect_bottleneck "system" "memory" "Memory usage ${mem_usage}%"
    fi
    
    # Disk usage
    local disk_usage=$(df -h /tmp | tail -1 | awk '{print $5}' | sed 's/%//' 2>/dev/null || echo "0")
    if [[ $disk_usage -gt 90 ]]; then
        status=$STATUS_DEGRADED
        issues+=("High disk usage: ${disk_usage}%")
        detect_bottleneck "system" "disk" "Disk usage ${disk_usage}%"
    fi
    
    record_health_status "system" "$status" "${issues[@]}"
    echo "$status"
}

# Pattern health check
check_pattern_health() {
    local pattern="$1"
    local pattern_file="$HEALTH_DATA_DIR/patterns/${pattern}.status"
    
    # Check if pattern has recent activity
    if [[ -f "$pattern_file" ]]; then
        local last_update=$(stat -f %m "$pattern_file" 2>/dev/null || stat -c %Y "$pattern_file" 2>/dev/null || echo 0)
        local current_time=$(date +%s)
        local age=$((current_time - last_update))
        
        if [[ $age -lt 300 ]]; then  # Active within 5 minutes
            return 0
        fi
    fi
    
    return 1
}

# Bottleneck detection
detect_bottleneck() {
    local component="$1"
    local bottleneck_type="$2"
    local description="$3"
    
    local bottleneck_id="${component}_${bottleneck_type}_$(date +%s)"
    local bottleneck_file="$HEALTH_DATA_DIR/bottlenecks/${bottleneck_id}.json"
    
    cat > "$bottleneck_file" <<EOF
{
    "id": "$bottleneck_id",
    "component": "$component",
    "type": "$bottleneck_type",
    "description": "$description",
    "detected_at": $(date +%s%N),
    "severity": "$(calculate_severity "$component" "$bottleneck_type")"
}
EOF
    
    # Trigger automated remediation if enabled
    if [[ "${AUTO_REMEDIATION:-false}" == "true" ]]; then
        remediate_bottleneck "$component" "$bottleneck_type"
    fi
    
    # Record telemetry
    if [[ -x "$TELEMETRY_SCRIPT" ]]; then
        "$TELEMETRY_SCRIPT" metric "swarmsh.health.bottleneck_detected" "1" "counter" \
            "{\"component\": \"$component\", \"type\": \"$bottleneck_type\"}"
    fi
}

# Calculate bottleneck severity
calculate_severity() {
    local component="$1"
    local bottleneck_type="$2"
    
    # Simple severity calculation based on component and type
    case "${component}_${bottleneck_type}" in
        "system_cpu"|"system_memory")
            echo "critical"
            ;;
        "work_queue_stuck"|"agents_failure")
            echo "high"
            ;;
        "telemetry_span_accumulation"|"work_queue_backlog")
            echo "medium"
            ;;
        *)
            echo "low"
            ;;
    esac
}

# Automated remediation
remediate_bottleneck() {
    local component="$1"
    local bottleneck_type="$2"
    
    echo "Attempting automated remediation for $component:$bottleneck_type"
    
    case "${component}_${bottleneck_type}" in
        "work_queue_stuck")
            # Reassign stuck work items
            remediate_stuck_work
            ;;
        "telemetry_span_accumulation")
            # Force telemetry export
            remediate_telemetry_accumulation
            ;;
        "agents_failure")
            # Restart failed agents
            remediate_failed_agents
            ;;
        *)
            echo "No automated remediation available for $component:$bottleneck_type"
            ;;
    esac
}

# Remediation actions
remediate_stuck_work() {
    local work_dir="${WORK_DIR:-/tmp/swarmsh_work}"
    local reassigned=0
    
    find "$work_dir" -name "*.claimed_*" -mmin +30 2>/dev/null | while read -r stuck_file; do
        local work_id=$(basename "$stuck_file" | cut -d'.' -f1)
        local new_file="${work_dir}/${work_id}.todo"
        
        if mv "$stuck_file" "$new_file" 2>/dev/null; then
            ((reassigned++))
            echo "Reassigned stuck work: $work_id"
        fi
    done
    
    echo "Remediation complete: $reassigned work items reassigned"
}

remediate_telemetry_accumulation() {
    if [[ -x "$TELEMETRY_SCRIPT" ]]; then
        "$TELEMETRY_SCRIPT" export json "/tmp/swarmsh_telemetry_forced_$(date +%s).json"
        
        # Clean old telemetry
        find "${TELEMETRY_DIR:-/tmp/swarmsh_telemetry}" -name "*.json" -mmin +60 -delete 2>/dev/null || true
        
        echo "Remediation complete: Telemetry exported and cleaned"
    fi
}

remediate_failed_agents() {
    local restarted=0
    
    for agent_file in /tmp/swarmsh_agents/*/config.json; do
        [[ -f "$agent_file" ]] || continue
        
        local agent_dir=$(dirname "$agent_file")
        local heartbeat_file="$agent_dir/heartbeat"
        
        if [[ ! -f "$heartbeat_file" ]] || [[ $(find "$heartbeat_file" -mmin +5 2>/dev/null | wc -l) -gt 0 ]]; then
            # Agent appears dead, mark for restart
            touch "$agent_dir/restart_required"
            ((restarted++))
        fi
    done
    
    echo "Remediation complete: $restarted agents marked for restart"
}

# Record health status
record_health_status() {
    local component="$1"
    local status="$2"
    shift 2
    local details="$*"
    
    local status_file="$HEALTH_DATA_DIR/components/${component}.json"
    mkdir -p "$(dirname "$status_file")"
    
    cat > "$status_file" <<EOF
{
    "component": "$component",
    "status": "$status",
    "details": "$details",
    "checked_at": $(date +%s%N),
    "check_duration_ns": 0
}
EOF
}

record_agent_health() {
    local agent_id="$1"
    local status="$2"
    local message="$3"
    
    local health_file="$HEALTH_DATA_DIR/agents/${agent_id}.json"
    mkdir -p "$(dirname "$health_file")"
    
    cat > "$health_file" <<EOF
{
    "agent_id": "$agent_id",
    "status": "$status",
    "message": "$message",
    "checked_at": $(date +%s%N)
}
EOF
}

# Health monitoring loop
start_health_monitor() {
    local interval="${1:-$HEALTH_CHECK_INTERVAL}"
    
    echo "Starting health monitor (interval: ${interval}s)"
    
    while true; do
        local check_start=$(date +%s%N)
        
        # Check all components
        local overall_status=$STATUS_HEALTHY
        
        for component in coordinator agents work_queue telemetry system; do
            local component_status=$(check_component_health "$component" "full")
            
            case "$component_status" in
                "$STATUS_CRITICAL")
                    overall_status=$STATUS_CRITICAL
                    ;;
                "$STATUS_DEGRADED")
                    if [[ "$overall_status" != "$STATUS_CRITICAL" ]]; then
                        overall_status=$STATUS_DEGRADED
                    fi
                    ;;
            esac
        done
        
        # Record overall health
        record_health_status "overall" "$overall_status" "Health check complete"
        
        # Generate health report
        if [[ "${HEALTH_REPORT_ENABLED:-true}" == "true" ]]; then
            generate_health_report
        fi
        
        local check_end=$(date +%s%N)
        local check_duration=$(( (check_end - check_start) / 1000000 ))  # Convert to ms
        
        echo "Health check complete: $overall_status (${check_duration}ms)"
        
        sleep "$interval"
    done &
    
    local monitor_pid=$!
    echo "$monitor_pid" > "$HEALTH_DATA_DIR/monitor.pid"
    echo "Health monitor started (PID: $monitor_pid)"
}

# Generate health report
generate_health_report() {
    local report_file="$HEALTH_DATA_DIR/reports/health_report_$(date +%s).json"
    mkdir -p "$(dirname "$report_file")"
    
    # Collect all health data
    local components=()
    for status_file in "$HEALTH_DATA_DIR/components"/*.json; do
        [[ -f "$status_file" ]] && components+=("$(cat "$status_file")")
    done
    
    local bottlenecks=()
    for bottleneck_file in "$HEALTH_DATA_DIR/bottlenecks"/*.json; do
        [[ -f "$bottleneck_file" ]] && bottlenecks+=("$(cat "$bottleneck_file")")
    done
    
    # Generate report
    jq -n \
        --argjson components "$(printf '%s\n' "${components[@]}" | jq -s '.')" \
        --argjson bottlenecks "$(printf '%s\n' "${bottlenecks[@]}" | jq -s '.')" \
        '{
            report_time: now,
            components: $components,
            bottlenecks: $bottlenecks,
            recommendations: []
        }' > "$report_file"
}

# Main health monitoring interface
main() {
    local command="${1:-help}"
    shift || true
    
    case "$command" in
        "check")
            if [[ $# -lt 1 ]]; then
                echo "Usage: $0 check <component> [check_type]"
                return 1
            fi
            check_component_health "$@"
            ;;
        "monitor")
            start_health_monitor "$@"
            ;;
        "bottleneck")
            if [[ $# -lt 3 ]]; then
                echo "Usage: $0 bottleneck <component> <type> <description>"
                return 1
            fi
            detect_bottleneck "$@"
            ;;
        "remediate")
            if [[ $# -lt 2 ]]; then
                echo "Usage: $0 remediate <component> <bottleneck_type>"
                return 1
            fi
            remediate_bottleneck "$@"
            ;;
        "report")
            generate_health_report
            echo "Health report generated"
            ;;
        "status")
            # Show current health status
            for component in coordinator agents work_queue telemetry system overall; do
                local status_file="$HEALTH_DATA_DIR/components/${component}.json"
                if [[ -f "$status_file" ]]; then
                    local status=$(jq -r '.status' "$status_file")
                    local details=$(jq -r '.details' "$status_file")
                    printf "%-15s: %-10s %s\n" "$component" "$status" "$details"
                fi
            done
            ;;
        "help")
            echo "SwarmSH v2 Health Monitor - Shell Export"
            echo "Usage: $0 <command> [args...]"
            echo ""
            echo "Commands:"
            echo "  check <component> [type]      - Check component health"
            echo "  monitor [interval]            - Start health monitor loop"
            echo "  bottleneck <comp> <type> <desc> - Report bottleneck"
            echo "  remediate <comp> <type>       - Trigger remediation"
            echo "  report                        - Generate health report"
            echo "  status                        - Show current status"
            echo "  help                          - Show this help"
            echo ""
            echo "Components: coordinator, agents, work_queue, telemetry, system"
            echo "Adaptive health monitoring with bottleneck detection"
            ;;
        *)
            echo "Unknown command: $command"
            echo "Use '$0 help' for usage information"
            return 1
            ;;
    esac
}

# Execute main function if called directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi