#!/bin/bash
# Generated by SwarmSH v2 Shell Exporter - Analytics DLSS Module
# Design for Lean Six Sigma Analytics Engine - $(date)
# Version: 2.0.0

set -euo pipefail

# SwarmSH v2 Analytics Engine with DLSS Optimization
# 8020 principle with 7 wastes elimination

# Configuration
ANALYTICS_DIR="${ANALYTICS_DIR:-/tmp/swarmsh_analytics}"
TELEMETRY_DIR="${TELEMETRY_DIR:-/tmp/swarmsh_telemetry}"
ANALYSIS_INTERVAL="${ANALYSIS_INTERVAL:-60}"
FLOW_EFFICIENCY_TARGET="${FLOW_EFFICIENCY_TARGET:-0.84}"

# DLSS Constants
readonly SEVEN_WASTES=(
    "overproduction"
    "waiting"
    "transport"
    "inappropriate_processing"
    "unnecessary_inventory"
    "unnecessary_motion"
    "defects"
)

# Ensure analytics directory exists
mkdir -p "$ANALYTICS_DIR"/{reports,waste,pareto,value_stream}

# Value Stream Mapping
create_value_stream_map() {
    local process_name="$1"
    local start_time="${2:-$(date -d '1 hour ago' +%s%N 2>/dev/null || date +%s%N)}"
    local end_time="${3:-$(date +%s%N)}"
    
    echo "Creating value stream map for: $process_name"
    
    local vsm_file="$ANALYTICS_DIR/value_stream/${process_name}_$(date +%s).json"
    
    # Analyze spans to build value stream
    local spans=$(find "$TELEMETRY_DIR/spans" -name "*.json" -newer "$ANALYTICS_DIR/.last_analysis" 2>/dev/null || \
                  find "$TELEMETRY_DIR/spans" -name "*.json" 2>/dev/null)
    
    local total_time=0
    local value_add_time=0
    local wait_time=0
    local steps=()
    
    # Process each span
    while IFS= read -r span_file; do
        [[ -f "$span_file" ]] || continue
        
        local span=$(cat "$span_file")
        local span_name=$(echo "$span" | jq -r '.name')
        local start=$(echo "$span" | jq -r '.start_time // 0')
        local end=$(echo "$span" | jq -r '.end_time // 0')
        
        if [[ "$end" != "null" ]] && [[ "$end" -gt 0 ]]; then
            local duration=$((end - start))
            total_time=$((total_time + duration))
            
            # Classify as value-add or waste
            if is_value_add_activity "$span_name"; then
                value_add_time=$((value_add_time + duration))
                local step_type="value_add"
            else
                wait_time=$((wait_time + duration))
                local step_type="waste"
            fi
            
            steps+=("{\"name\": \"$span_name\", \"duration\": $duration, \"type\": \"$step_type\"}")
        fi
    done <<< "$spans"
    
    # Calculate flow efficiency
    local flow_efficiency=0
    if [[ $total_time -gt 0 ]]; then
        flow_efficiency=$(echo "scale=4; $value_add_time / $total_time" | bc)
    fi
    
    # Generate VSM
    cat > "$vsm_file" <<EOF
{
    "process": "$process_name",
    "total_time_ns": $total_time,
    "value_add_time_ns": $value_add_time,
    "wait_time_ns": $wait_time,
    "flow_efficiency": $flow_efficiency,
    "target_efficiency": $FLOW_EFFICIENCY_TARGET,
    "steps": [$(IFS=,; echo "${steps[*]}")]
}
EOF
    
    echo "Value stream map created: $vsm_file"
    echo "Flow efficiency: $(echo "$flow_efficiency * 100" | bc)%"
    
    # Check against target
    if (( $(echo "$flow_efficiency < $FLOW_EFFICIENCY_TARGET" | bc -l) )); then
        echo "WARNING: Flow efficiency below target (${FLOW_EFFICIENCY_TARGET})"
        identify_improvement_opportunities "$vsm_file"
    fi
}

# Check if activity adds value
is_value_add_activity() {
    local activity="$1"
    
    # Value-add patterns
    case "$activity" in
        *"work"*|*"process"*|*"execute"*|*"transform"*)
            return 0
            ;;
        *"wait"*|*"queue"*|*"retry"*|*"idle"*)
            return 1
            ;;
        *)
            # Default: consider coordination as non-value-add
            return 1
            ;;
    esac
}

# Waste Detection
detect_waste() {
    local waste_type="${1:-all}"
    local time_window="${2:-3600}"  # Default: last hour
    
    echo "Detecting waste: $waste_type"
    
    if [[ "$waste_type" == "all" ]]; then
        for waste in "${SEVEN_WASTES[@]}"; do
            detect_specific_waste "$waste" "$time_window"
        done
    else
        detect_specific_waste "$waste_type" "$time_window"
    fi
}

detect_specific_waste() {
    local waste_type="$1"
    local time_window="$2"
    
    local waste_file="$ANALYTICS_DIR/waste/${waste_type}_$(date +%s).json"
    local instances=()
    local total_impact=0
    
    case "$waste_type" in
        "overproduction")
            # Detect work created but not consumed
            local unclaimed_work=$(find /tmp/swarmsh_work -name "*.todo" -mmin +$((time_window/60)) 2>/dev/null | wc -l)
            if [[ $unclaimed_work -gt 0 ]]; then
                instances+=("{\"type\": \"unclaimed_work\", \"count\": $unclaimed_work, \"impact\": \"high\"}")
                total_impact=$((total_impact + unclaimed_work * 100))
            fi
            ;;
            
        "waiting")
            # Detect idle agents
            local idle_agents=$(find /tmp/swarmsh_agents -name "heartbeat" -mmin +1 2>/dev/null | wc -l)
            if [[ $idle_agents -gt 0 ]]; then
                instances+=("{\"type\": \"idle_agents\", \"count\": $idle_agents, \"impact\": \"medium\"}")
                total_impact=$((total_impact + idle_agents * 50))
            fi
            ;;
            
        "transport")
            # Detect unnecessary work reassignments
            local reassignments=$(find /tmp/swarmsh_work -name "*.reassigned_*" 2>/dev/null | wc -l)
            if [[ $reassignments -gt 0 ]]; then
                instances+=("{\"type\": \"work_reassignments\", \"count\": $reassignments, \"impact\": \"medium\"}")
                total_impact=$((total_impact + reassignments * 30))
            fi
            ;;
            
        "inappropriate_processing")
            # Detect overcomplex coordination patterns
            local complex_coords=$(find "$TELEMETRY_DIR/spans" -name "*.json" -exec grep -l "roberts_rules" {} \; 2>/dev/null | wc -l)
            if [[ $complex_coords -gt 10 ]]; then
                instances+=("{\"type\": \"overcomplex_coordination\", \"count\": $complex_coords, \"impact\": \"low\"}")
                total_impact=$((total_impact + complex_coords * 20))
            fi
            ;;
            
        "unnecessary_inventory")
            # Detect accumulated telemetry
            local old_telemetry=$(find "$TELEMETRY_DIR" -name "*.json" -mmin +$((time_window/60)) 2>/dev/null | wc -l)
            if [[ $old_telemetry -gt 1000 ]]; then
                instances+=("{\"type\": \"telemetry_accumulation\", \"count\": $old_telemetry, \"impact\": \"low\"}")
                total_impact=$((total_impact + old_telemetry / 10))
            fi
            ;;
            
        "unnecessary_motion")
            # Detect excessive coordination overhead
            local coord_spans=$(find "$TELEMETRY_DIR/spans" -name "*.json" -exec grep -c "coordination" {} \; 2>/dev/null | \
                               awk '{sum+=$1} END {print sum}')
            if [[ ${coord_spans:-0} -gt 100 ]]; then
                instances+=("{\"type\": \"excessive_coordination\", \"count\": $coord_spans, \"impact\": \"medium\"}")
                total_impact=$((total_impact + coord_spans * 10))
            fi
            ;;
            
        "defects")
            # Detect failed work items
            local failed_work=$(find /tmp/swarmsh_work -name "*.failed_*" 2>/dev/null | wc -l)
            if [[ $failed_work -gt 0 ]]; then
                instances+=("{\"type\": \"work_failures\", \"count\": $failed_work, \"impact\": \"high\"}")
                total_impact=$((total_impact + failed_work * 200))
            fi
            ;;
    esac
    
    # Record waste analysis
    cat > "$waste_file" <<EOF
{
    "waste_type": "$waste_type",
    "detected_at": $(date +%s%N),
    "time_window_seconds": $time_window,
    "instances": [$(IFS=,; echo "${instances[*]}")],
    "total_impact_score": $total_impact,
    "recommendations": $(generate_waste_recommendations "$waste_type" "$total_impact")
}
EOF
    
    echo "Waste analysis complete: $waste_type (impact: $total_impact)"
}

# Generate waste reduction recommendations
generate_waste_recommendations() {
    local waste_type="$1"
    local impact_score="$2"
    
    local recommendations=()
    
    case "$waste_type" in
        "overproduction")
            recommendations+=("\"Implement pull-based work assignment\"")
            recommendations+=("\"Reduce work batch sizes\"")
            ;;
        "waiting")
            recommendations+=("\"Increase agent capacity\"")
            recommendations+=("\"Improve work distribution algorithm\"")
            ;;
        "transport")
            recommendations+=("\"Implement sticky work assignment\"")
            recommendations+=("\"Reduce coordination overhead\"")
            ;;
        "inappropriate_processing")
            recommendations+=("\"Simplify coordination patterns\"")
            recommendations+=("\"Use appropriate pattern for workload\"")
            ;;
        "unnecessary_inventory")
            recommendations+=("\"Implement telemetry rotation\"")
            recommendations+=("\"Reduce data retention period\"")
            ;;
        "unnecessary_motion")
            recommendations+=("\"Batch coordination operations\"")
            recommendations+=("\"Reduce synchronization frequency\"")
            ;;
        "defects")
            recommendations+=("\"Implement error recovery\"")
            recommendations+=("\"Add work validation\"")
            ;;
    esac
    
    echo "[$(IFS=,; echo "${recommendations[*]}")]"
}

# Pareto Analysis (80/20)
perform_pareto_analysis() {
    local analysis_type="${1:-bottlenecks}"
    local time_window="${2:-3600}"
    
    echo "Performing Pareto analysis: $analysis_type"
    
    local pareto_file="$ANALYTICS_DIR/pareto/${analysis_type}_$(date +%s).json"
    local data_points=()
    
    case "$analysis_type" in
        "bottlenecks")
            analyze_bottleneck_pareto "$time_window"
            ;;
        "work_distribution")
            analyze_work_distribution_pareto "$time_window"
            ;;
        "agent_performance")
            analyze_agent_performance_pareto "$time_window"
            ;;
        "error_patterns")
            analyze_error_patterns_pareto "$time_window"
            ;;
    esac
}

# Analyze bottlenecks using Pareto principle
analyze_bottleneck_pareto() {
    local time_window="$1"
    local bottlenecks_file="$ANALYTICS_DIR/pareto/bottlenecks_$(date +%s).json"
    
    # Collect bottleneck data
    local bottleneck_counts=()
    
    # Count by component
    for component in coordinator agents work_queue telemetry system; do
        local count=$(find "$HEALTH_DATA_DIR/bottlenecks" -name "*${component}*" -mmin -$((time_window/60)) 2>/dev/null | wc -l)
        if [[ $count -gt 0 ]]; then
            bottleneck_counts+=("{\"component\": \"$component\", \"count\": $count}")
        fi
    done
    
    # Sort and identify top 20% causing 80% of issues
    local sorted_bottlenecks=$(echo "${bottleneck_counts[@]}" | jq -s 'sort_by(.count) | reverse')
    local total_count=$(echo "$sorted_bottlenecks" | jq '[.[].count] | add')
    local cumulative=0
    local vital_few=()
    
    echo "$sorted_bottlenecks" | jq -c '.[]' | while read -r item; do
        local count=$(echo "$item" | jq '.count')
        cumulative=$((cumulative + count))
        local percentage=$(echo "scale=2; $cumulative * 100 / $total_count" | bc)
        
        vital_few+=("$item")
        
        if (( $(echo "$percentage >= 80" | bc -l) )); then
            break
        fi
    done
    
    # Generate Pareto report
    cat > "$bottlenecks_file" <<EOF
{
    "analysis_type": "bottlenecks",
    "total_incidents": $total_count,
    "vital_few": [$(IFS=,; echo "${vital_few[*]}")],
    "recommendation": "Focus on these components for maximum impact",
    "generated_at": $(date +%s%N)
}
EOF
    
    echo "Pareto analysis complete: Top components causing 80% of bottlenecks identified"
}

# Quality Control Charts
generate_quality_charts() {
    local metric_name="$1"
    local control_limits="${2:-3}"  # Default: 3-sigma
    
    echo "Generating quality control chart for: $metric_name"
    
    local chart_file="$ANALYTICS_DIR/reports/control_chart_${metric_name}_$(date +%s).json"
    
    # Collect metric data
    local metric_values=()
    find "$TELEMETRY_DIR/metrics" -name "${metric_name}*.json" -mmin -60 2>/dev/null | while read -r metric_file; do
        local value=$(jq -r '.value' "$metric_file" 2>/dev/null)
        [[ -n "$value" ]] && metric_values+=("$value")
    done
    
    if [[ ${#metric_values[@]} -eq 0 ]]; then
        echo "No data available for metric: $metric_name"
        return 1
    fi
    
    # Calculate statistics
    local mean=$(printf '%s\n' "${metric_values[@]}" | awk '{sum+=$1} END {print sum/NR}')
    local stddev=$(printf '%s\n' "${metric_values[@]}" | awk -v mean="$mean" '{sum+=($1-mean)^2} END {print sqrt(sum/NR)}')
    
    # Calculate control limits
    local ucl=$(echo "$mean + $control_limits * $stddev" | bc -l)
    local lcl=$(echo "$mean - $control_limits * $stddev" | bc -l)
    
    # Identify out-of-control points
    local violations=0
    local violation_points=()
    
    for value in "${metric_values[@]}"; do
        if (( $(echo "$value > $ucl || $value < $lcl" | bc -l) )); then
            ((violations++))
            violation_points+=("$value")
        fi
    done
    
    # Generate control chart
    cat > "$chart_file" <<EOF
{
    "metric": "$metric_name",
    "sample_size": ${#metric_values[@]},
    "mean": $mean,
    "std_dev": $stddev,
    "upper_control_limit": $ucl,
    "lower_control_limit": $lcl,
    "control_limit_sigma": $control_limits,
    "violations": $violations,
    "violation_rate": $(echo "scale=4; $violations / ${#metric_values[@]}" | bc),
    "process_capability": $(calculate_process_capability "$mean" "$stddev" "$ucl" "$lcl"),
    "generated_at": $(date +%s%N)
}
EOF
    
    echo "Control chart generated: $chart_file"
    echo "Process violations: $violations out of ${#metric_values[@]} samples"
}

# Calculate process capability
calculate_process_capability() {
    local mean="$1"
    local stddev="$2"
    local ucl="$3"
    local lcl="$4"
    
    # Cp = (USL - LSL) / (6 * sigma)
    local cp=$(echo "scale=4; ($ucl - $lcl) / (6 * $stddev)" | bc -l 2>/dev/null || echo "1.0")
    echo "$cp"
}

# Optimization recommendations
generate_optimization_report() {
    local report_file="$ANALYTICS_DIR/reports/optimization_$(date +%s).json"
    
    echo "Generating optimization report..."
    
    # Analyze recent data
    local flow_efficiency=$(find "$ANALYTICS_DIR/value_stream" -name "*.json" -mmin -60 2>/dev/null | \
                           xargs -I {} jq -r '.flow_efficiency' {} 2>/dev/null | \
                           awk '{sum+=$1; count++} END {if(count>0) print sum/count; else print 0}')
    
    local waste_impact=$(find "$ANALYTICS_DIR/waste" -name "*.json" -mmin -60 2>/dev/null | \
                        xargs -I {} jq -r '.total_impact_score' {} 2>/dev/null | \
                        awk '{sum+=$1} END {print sum}')
    
    # Generate recommendations
    local recommendations=()
    
    if (( $(echo "$flow_efficiency < $FLOW_EFFICIENCY_TARGET" | bc -l 2>/dev/null || echo 0) )); then
        recommendations+=("\"Improve flow efficiency from $(echo "$flow_efficiency * 100" | bc)% to $(echo "$FLOW_EFFICIENCY_TARGET * 100" | bc)%\"")
        recommendations+=("\"Reduce wait time in coordination cycles\"")
    fi
    
    if [[ ${waste_impact:-0} -gt 1000 ]]; then
        recommendations+=("\"High waste detected (score: $waste_impact) - implement waste reduction\"")
        recommendations+=("\"Focus on top waste categories identified in Pareto analysis\"")
    fi
    
    # Generate report
    cat > "$report_file" <<EOF
{
    "report_type": "optimization",
    "generated_at": $(date +%s%N),
    "current_metrics": {
        "flow_efficiency": ${flow_efficiency:-0},
        "waste_impact_score": ${waste_impact:-0},
        "bottleneck_count": $(find "$HEALTH_DATA_DIR/bottlenecks" -name "*.json" -mmin -60 2>/dev/null | wc -l)
    },
    "targets": {
        "flow_efficiency": $FLOW_EFFICIENCY_TARGET,
        "waste_reduction": 0.5,
        "defect_rate": 0.001
    },
    "recommendations": [$(IFS=,; echo "${recommendations[*]}")],
    "expected_improvement": "20-30% efficiency gain with recommended changes"
}
EOF
    
    echo "Optimization report generated: $report_file"
}

# Analytics daemon
start_analytics_daemon() {
    local interval="${1:-$ANALYSIS_INTERVAL}"
    
    echo "Starting analytics daemon (interval: ${interval}s)"
    
    while true; do
        sleep "$interval"
        
        # Run analytics cycle
        echo "Running analytics cycle..."
        
        # Value stream analysis
        create_value_stream_map "coordination_flow"
        
        # Waste detection
        detect_waste "all"
        
        # Pareto analysis
        perform_pareto_analysis "bottlenecks"
        
        # Generate optimization report
        generate_optimization_report
        
        # Mark analysis timestamp
        touch "$ANALYTICS_DIR/.last_analysis"
        
        echo "Analytics cycle complete"
    done &
    
    local daemon_pid=$!
    echo "$daemon_pid" > "$ANALYTICS_DIR/daemon.pid"
    echo "Analytics daemon started (PID: $daemon_pid)"
}

# Main analytics interface
main() {
    local command="${1:-help}"
    shift || true
    
    case "$command" in
        "vsm")
            create_value_stream_map "$@"
            ;;
        "waste")
            detect_waste "$@"
            ;;
        "pareto")
            perform_pareto_analysis "$@"
            ;;
        "control")
            if [[ $# -lt 1 ]]; then
                echo "Usage: $0 control <metric_name> [sigma_level]"
                return 1
            fi
            generate_quality_charts "$@"
            ;;
        "optimize")
            generate_optimization_report
            ;;
        "daemon")
            start_analytics_daemon "$@"
            ;;
        "help")
            echo "SwarmSH v2 Analytics DLSS Engine - Shell Export"
            echo "Usage: $0 <command> [args...]"
            echo ""
            echo "Commands:"
            echo "  vsm <process> [start] [end]   - Create value stream map"
            echo "  waste [type] [window]         - Detect waste (7 types)"
            echo "  pareto <analysis_type>        - 80/20 analysis"
            echo "  control <metric> [sigma]      - Quality control charts"
            echo "  optimize                      - Generate optimization report"
            echo "  daemon [interval]             - Start analytics daemon"
            echo "  help                          - Show this help"
            echo ""
            echo "DLSS optimization with $(echo "$FLOW_EFFICIENCY_TARGET * 100" | bc)% flow efficiency target"
            ;;
        *)
            echo "Unknown command: $command"
            echo "Use '$0 help' for usage information"
            return 1
            ;;
    esac
}

# Execute main function if called directly
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi