//! SwarmSH 80/20 Automation CLI
//! 
//! Implements the 20% of automation features that deliver 80% of the value:
//! - Health monitoring (prevents system failures)
//! - Work queue optimization (maintains performance)  
//! - Metrics collection (provides visibility)
//!
//! This is the Rust equivalent of the shell-based 8020_cron_automation.sh

use swarmsh_v2::{
    coordination::{AgentCoordinator, CoordinationPattern},
    health::{HealthMonitor, HealthStatus},
    analytics::{AnalyticsEngine},
    telemetry::{SwarmTelemetry, DefaultSwarmTelemetry, TelemetryManager, CorrelationId},
    shell_export::{ShellExporter, ExportConfig},
    SwarmResult,
};
use clap::{Parser, Subcommand};
use serde_json::{json, Value};
use std::path::PathBuf;
use std::time::{Instant, SystemTime, UNIX_EPOCH};
use tokio::fs;
use tracing::{info, warn, debug, instrument, span, Level};
use anyhow::Result;

#[derive(Parser)]
#[command(name = "swarmsh-automation")]
#[command(about = "SwarmSH 80/20 Automation - High-Impact Scheduled Tasks")]
#[command(version = "2.0.0")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
    
    /// Coordination directory path
    #[arg(long, default_value = "/tmp/swarmsh-coordination")]
    coordination_dir: PathBuf,
    
    /// Log directory path
    #[arg(long, default_value = "/tmp/swarmsh-logs")]
    log_dir: PathBuf,
    
    /// Enable JSON output
    #[arg(long)]
    json: bool,
}

#[derive(Subcommand)]
enum Commands {
    /// Run health monitoring check (80/20: prevents failures)
    Health {
        /// Generate detailed health report
        #[arg(long)]
        detailed: bool,
    },
    /// Run work queue optimization (80/20: maintains performance)
    Optimize {
        /// Force optimization even if thresholds not met
        #[arg(long)]
        force: bool,
    },
    /// Collect system metrics (80/20: provides visibility)
    Metrics {
        /// Export metrics to specific format
        #[arg(long, value_enum)]
        format: Option<MetricsFormat>,
    },
    /// Install cron jobs for automation
    Install,
    /// Show automation status
    Status,
    /// Export automation functionality to shell scripts
    Export {
        /// Output directory for shell scripts
        #[arg(long, default_value = "./shell-export")]
        output_dir: PathBuf,
    },
}

#[derive(clap::ValueEnum, Clone)]
enum MetricsFormat {
    Json,
    Prometheus,
    Otel,
}

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_env_filter("swarmsh_automation=debug,swarmsh_v2=info")
        .init();

    let cli = Cli::parse();
    
    // Initialize telemetry
    let telemetry = DefaultSwarmTelemetry::default();
    let correlation_id = CorrelationId::new();
    
    // Create coordination directories
    tokio::fs::create_dir_all(&cli.coordination_dir).await?;
    tokio::fs::create_dir_all(&cli.log_dir).await?;
    
    let automation = SwarmShAutomation::new(
        cli.coordination_dir.clone(),
        cli.log_dir.clone(),
        telemetry,
    ).await?;
    
    let result = match cli.command {
        Commands::Health { detailed } => {
            automation.run_health_monitoring(detailed, correlation_id).await
        }
        Commands::Optimize { force } => {
            automation.run_optimization(force, correlation_id).await
        }
        Commands::Metrics { format } => {
            automation.run_metrics_collection(format, correlation_id).await
        }
        Commands::Install => {
            automation.install_cron_jobs().await
        }
        Commands::Status => {
            automation.show_status().await
        }
        Commands::Export { output_dir } => {
            automation.export_to_shell(output_dir).await
        }
    };
    
    match result {
        Ok(_) => {
            if cli.json {
                println!("{}", json!({"status": "success", "correlation_id": correlation_id.to_string()}));
            }
            Ok(())
        }
        Err(e) => {
            if cli.json {
                println!("{}", json!({"status": "error", "error": e.to_string(), "correlation_id": correlation_id.to_string()}));
            } else {
                eprintln!("Error: {}", e);
            }
            std::process::exit(1);
        }
    }
}

struct SwarmShAutomation {
    coordination_dir: PathBuf,
    log_dir: PathBuf,
    telemetry: DefaultSwarmTelemetry,
    health_monitor: HealthMonitor,
    analytics: AnalyticsEngine,
}

impl SwarmShAutomation {
    async fn new(
        coordination_dir: PathBuf,
        log_dir: PathBuf,
        telemetry: DefaultSwarmTelemetry,
    ) -> Result<Self> {
        let health_monitor = HealthMonitor::new().await?;
        let telemetry_manager = std::sync::Arc::new(TelemetryManager::new().await?);
        let analytics = AnalyticsEngine::new(telemetry_manager).await?;
        
        Ok(Self {
            coordination_dir,
            log_dir,
            telemetry,
            health_monitor,
            analytics,
        })
    }
    
    /// 80/20 FEATURE 1: Health Monitoring (High Impact - Prevents Failures)
    #[instrument(skip(self), fields(correlation_id = %correlation_id))]
    async fn run_health_monitoring(&self, detailed: bool, correlation_id: CorrelationId) -> Result<()> {
        let _span = self.telemetry.span_with_correlation("automation_health_check", &correlation_id).entered();
        let start_time = Instant::now();
        
        info!("üè• Starting 80/20 health monitoring");
        
        // Use SwarmSH health monitor
        let health_report = self.health_monitor.check_system_health().await?;
        let health_score = match health_report.status {
            HealthStatus::Healthy => 100,
            HealthStatus::Degraded => 75,
            HealthStatus::Critical => 25,
            HealthStatus::Failed => 0,
        };
        
        // Additional checks specific to automation
        let mut issues = Vec::new();
        
        // Check work queue size
        let work_claims_path = self.coordination_dir.join("work_claims.json");
        if work_claims_path.exists() {
            let content = fs::read_to_string(&work_claims_path).await?;
            let work_count = content.matches("work_item_id").count();
            if work_count > 100 {
                issues.push(format!("High work queue size: {} items", work_count));
            }
        }
        
        // Check agent status freshness
        let agent_status_path = self.coordination_dir.join("agent_status.json");
        if agent_status_path.exists() {
            let metadata = fs::metadata(&agent_status_path).await?;
            let age = SystemTime::now().duration_since(metadata.modified()?)?.as_secs();
            if age > 3600 { // 1 hour
                issues.push(format!("Agent status file stale: {}s old", age));
            }
        }
        
        // Create health report
        let report = json!({
            "timestamp": SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs(),
            "health_score": health_score,
            "status": format!("{:?}", health_report.status),
            "issues": issues,
            "detailed_report": if detailed { Some(&health_report) } else { None },
            "telemetry": {
                "correlation_id": correlation_id.to_string(),
                "operation": "swarmsh.automation.health",
                "duration_ms": start_time.elapsed().as_millis()
            }
        });
        
        // Save report
        let report_path = self.log_dir.join(format!("health_report_{}.json", 
            SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs()));
        fs::write(&report_path, serde_json::to_string_pretty(&report)?).await?;
        
        // Log telemetry with semantic conventions
        self.telemetry.record_health_check("system", "completed", start_time.elapsed());
        
        info!("‚úÖ Health monitoring complete ({:?}) - Score: {}/100, Report: {:?}", 
            start_time.elapsed(), health_score, report_path);
        
        Ok(())
    }
    
    /// 80/20 FEATURE 2: Work Queue Optimization (High Impact - Maintains Performance)
    #[instrument(skip(self), fields(correlation_id = %correlation_id))]
    async fn run_optimization(&self, force: bool, correlation_id: CorrelationId) -> Result<()> {
        let _span = self.telemetry.span_with_correlation("automation_optimization", &correlation_id).entered();
        let start_time = Instant::now();
        
        info!("‚ö° Starting 80/20 work queue optimization");
        
        let mut optimizations = 0;
        
        // Optimize fast-path files
        let fast_path = self.coordination_dir.join("work_claims_fast.jsonl");
        if fast_path.exists() {
            let content = fs::read_to_string(&fast_path).await?;
            let line_count = content.lines().count();
            
            if line_count > 100 || force {
                info!("üîÑ Optimizing fast-path file ({} entries)", line_count);
                let lines: Vec<&str> = content.lines().collect();
                let optimized_content = lines.iter().rev().take(50).rev().cloned().collect::<Vec<_>>().join("\n");
                fs::write(&fast_path, optimized_content).await?;
                optimizations += 1;
                info!("‚úÖ Fast-path file optimized (kept latest 50 entries)");
            }
        }
        
        // Clean up completed work using analytics engine
        let waste_metrics = self.analytics.get_waste_metrics().await?;
        if waste_metrics.get("completed_work_retention").unwrap_or(&0.0) > &50.0 || force {
            info!("üßπ Cleaning completed work items");
            // Implementation would use coordination engine to clean up completed work
            optimizations += 1;
        }
        
        // Log telemetry with semantic conventions
        self.telemetry.record_coordination_duration("optimization", start_time.elapsed());
        
        info!("‚úÖ Work queue optimization complete ({:?}) - Applied {} optimizations", 
            start_time.elapsed(), optimizations);
        
        Ok(())
    }
    
    /// 80/20 FEATURE 3: Metrics Collection (Medium Impact - Provides Visibility)
    #[instrument(skip(self), fields(correlation_id = %correlation_id))]
    async fn run_metrics_collection(&self, format: Option<MetricsFormat>, correlation_id: CorrelationId) -> Result<()> {
        let _span = self.telemetry.span_with_correlation("automation_metrics", &correlation_id).entered();
        let start_time = Instant::now();
        
        info!("üìä Starting 80/20 metrics collection");
        
        // Collect work queue metrics
        let mut active_work = 0;
        let mut pending_work = 0;
        let mut completed_work = 0;
        
        let work_claims_path = self.coordination_dir.join("work_claims.json");
        if work_claims_path.exists() {
            let content = fs::read_to_string(&work_claims_path).await?;
            active_work = content.matches("\"status\":\"active\"").count();
            pending_work = content.matches("\"status\":\"pending\"").count();
            completed_work = content.matches("\"status\":\"completed\"").count();
        }
        
        // Collect agent metrics
        let mut active_agents = 0;
        let agent_status_path = self.coordination_dir.join("agent_status.json");
        if agent_status_path.exists() {
            let content = fs::read_to_string(&agent_status_path).await?;
            active_agents = content.matches("\"agent_id\"").count();
        }
        
        // Create metrics report
        let metrics = json!({
            "timestamp": SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs(),
            "work_queue": {
                "active": active_work,
                "pending": pending_work,
                "completed": completed_work,
                "total": active_work + pending_work + completed_work
            },
            "agents": {
                "active": active_agents
            },
            "telemetry": {
                "correlation_id": correlation_id.to_string(),
                "operation": "swarmsh.automation.metrics"
            }
        });
        
        // Save metrics report
        let metrics_path = self.log_dir.join(format!("metrics_{}.json", 
            SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs()));
        fs::write(&metrics_path, serde_json::to_string_pretty(&metrics)?).await?;
        
        // Export in requested format
        match format {
            Some(MetricsFormat::Prometheus) => {
                self.export_prometheus_metrics(&metrics).await?;
            }
            Some(MetricsFormat::Otel) => {
                self.export_otel_metrics(&metrics).await?;
            }
            _ => {} // JSON is default
        }
        
        // Log telemetry with semantic conventions
        self.telemetry.record_coordination_duration("metrics_collection", start_time.elapsed());
        
        info!("‚úÖ Metrics collection complete ({:?}) - Report: {:?}", 
            start_time.elapsed(), metrics_path);
        
        Ok(())
    }
    
    async fn export_prometheus_metrics(&self, metrics: &Value) -> Result<()> {
        // Implementation for Prometheus format export
        info!("üìä Exporting metrics in Prometheus format");
        Ok(())
    }
    
    async fn export_otel_metrics(&self, metrics: &Value) -> Result<()> {
        // Implementation for OTEL format export  
        info!("üìä Exporting metrics in OTEL format");
        Ok(())
    }
    
    async fn install_cron_jobs(&self) -> Result<()> {
        info!("üîß Installing 80/20 cron automation jobs");
        
        let cron_config = json!({
            "swarmsh_automation_jobs": {
                "health_monitoring": {
                    "schedule": "*/15 * * * *",
                    "command": "swarmsh-automation health",
                    "description": "Health monitoring every 15 minutes (prevents failures)"
                },
                "work_optimization": {
                    "schedule": "0 * * * *", 
                    "command": "swarmsh-automation optimize",
                    "description": "Work queue optimization every hour (maintains performance)"
                },
                "metrics_collection": {
                    "schedule": "*/30 * * * *",
                    "command": "swarmsh-automation metrics",
                    "description": "Metrics collection every 30 minutes (provides visibility)"
                }
            }
        });
        
        let cron_config_path = self.log_dir.join("cron_automation_config.json");
        fs::write(&cron_config_path, serde_json::to_string_pretty(&cron_config)?).await?;
        
        info!("‚úÖ Cron configuration written to {:?}", cron_config_path);
        info!("‚ÑπÔ∏è  Install with: crontab {:?}", cron_config_path);
        
        Ok(())
    }
    
    async fn show_status(&self) -> Result<()> {
        info!("üìã 80/20 Automation Status");
        
        // Show recent health reports
        let mut health_reports = Vec::new();
        let mut dir_entries = fs::read_dir(&self.log_dir).await?;
        while let Some(entry) = dir_entries.next_entry().await? {
            if entry.file_name().to_string_lossy().starts_with("health_report_") {
                health_reports.push(entry.path());
            }
        }
        health_reports.sort();
        
        println!("Recent Health Reports:");
        for report_path in health_reports.iter().rev().take(3) {
            println!("  {:?}", report_path);
        }
        
        Ok(())
    }
    
    /// Export automation functionality to shell scripts
    async fn export_to_shell(&self, output_dir: PathBuf) -> Result<()> {
        info!("üêö Exporting automation functionality to shell scripts");
        
        tokio::fs::create_dir_all(&output_dir).await?;
        
        // Create shell exporter with automation templates
        let export_config = ExportConfig {
            output_dir: output_dir.clone(),
            template_dir: PathBuf::from("templates"),
            enable_ai: true,
            optimization_level: "production".to_string(),
        };
        
        let shell_exporter = ShellExporter::new(export_config).await?;
        
        // Export automation scripts
        let automation_context = json!({
            "coordination_dir": self.coordination_dir,
            "log_dir": self.log_dir,
            "features": ["health", "optimize", "metrics"],
            "schedules": {
                "health": "*/15 * * * *",
                "optimize": "0 * * * *", 
                "metrics": "*/30 * * * *"
            }
        });
        
        shell_exporter.export_with_context(&automation_context).await?;
        
        info!("‚úÖ Automation scripts exported to {:?}", output_dir);
        
        Ok(())
    }
}